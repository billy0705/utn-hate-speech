
# utn-hate-speech

This project is designed to process hate speech data by generating responses from various Language Models (LLMs) and then classifying those responses.

## Setup

1.  Install the required Python packages:
    ```bash
    pip install -r requirements.txt
    ```

2.  Create a `.env` file in the root directory to store your API keys. For example:
    ```
    OPENAI_API_KEY="your_openai_api_key"
    ```

## Usage

The main script for interacting with the project is `main.py`.

### Arguments

*   `task`: The task to perform. (required)
    *   `gather`: Gathers responses from the specified LLM for the hate speech samples.
    *   `annotate`: Classifies the generated responses.
*   `--model`: The language model to use. (required)
    *   `chatgpt`: Uses the ChatGPT model.
    *   `deepseek`: Uses the DeepSeek model.
    *   `claude`: Uses the Claude model.
    *   `llama`: Uses a local Llama model (placeholder).
*   `--languages`: A list of languages to process (e.g., `English`, `Chinese`). If not provided, all available languages will be processed.
*   `--limit`: An integer to limit the number of items to process.
*   `--data_path`: The path to the data directory. Defaults to `database_building/data`.
*   `--env_file`: The path to the environment file. Defaults to `.env`.

### Examples

**Gathering Responses**

*   Gather responses for all samples using ChatGPT:
    ```bash
    python main.py gather --model chatgpt
    ```

*   Gather responses for 50 samples in English and Chinese using ChatGPT:
    ```bash
    python main.py gather --model chatgpt --languages English Chinese --limit 50
    ```

**Annotating Responses**

*   Annotate all responses generated by ChatGPT:
    ```bash
    python main.py annotate --model chatgpt
    ```

*   Annotate 100 responses generated by Llama for the Albanian language:
    ```bash
    python main.py annotate --model llama --languages Albanian --limit 100
    ```
